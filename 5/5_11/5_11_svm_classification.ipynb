{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.11. Klasyfikacja za pomocą SVM\n",
    "\n",
    "Powróćmy po raz kolejny do klasyfikacji niewypłacalności klientów. Spróbujemy, tym razem za pomocą SVM, rozwiązać kolejny raz ten sam problem. Jest to dość typowe zjawisko w przypadku tworzenia rozwiązań ML - należy stworzyć kilka modeli, aby później wybrać ten najlepszy, względnie wystarczająco dobry, ale wydajny. Poprzednio testowaliśmy KNN i jego wydajność dość mocno zależy od tego na jak wielu wektorach trenowaliśmy nasz model, co czyni go mało użytecznym gdy danych jest naprawdę sporo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ID</th>\n",
       "      <th>8223</th>\n",
       "      <th>3151</th>\n",
       "      <th>5714</th>\n",
       "      <th>4793</th>\n",
       "      <th>24536</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>52.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_1</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_2</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_3</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_4</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_5</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_6</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_OVERDUE_COUNT</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WEIGHTED_PAYMENT_HISTORY</th>\n",
       "      <td>-4.733333</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVG_PAY_AMT</th>\n",
       "      <td>3674.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1535.833333</td>\n",
       "      <td>1217.666667</td>\n",
       "      <td>2045.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEX_2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDUCATION_1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDUCATION_2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDUCATION_3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDUCATION_4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDUCATION_5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MARRIAGE_1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MARRIAGE_2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MARRIAGE_3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEFAULT</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ID                              8223   3151         5714         4793   \\\n",
       "AGE                         37.000000   52.0    22.000000    44.000000   \n",
       "PAY_1                       -2.000000   -2.0     3.000000     0.000000   \n",
       "PAY_2                       -2.000000   -2.0     2.000000     0.000000   \n",
       "PAY_3                       -2.000000   -2.0     0.000000     0.000000   \n",
       "PAY_4                       -2.000000   -2.0     0.000000     0.000000   \n",
       "PAY_5                       -2.000000   -2.0     2.000000     0.000000   \n",
       "PAY_6                       -1.000000   -2.0     2.000000     0.000000   \n",
       "PAY_OVERDUE_COUNT            0.000000    0.0     4.000000     0.000000   \n",
       "WEIGHTED_PAYMENT_HISTORY    -4.733333   -4.9     4.733333     0.000000   \n",
       "AVG_PAY_AMT               3674.500000    0.0  1535.833333  1217.666667   \n",
       "SEX_2                        1.000000    1.0     1.000000     0.000000   \n",
       "EDUCATION_1                  0.000000    0.0     0.000000     1.000000   \n",
       "EDUCATION_2                  1.000000    0.0     1.000000     0.000000   \n",
       "EDUCATION_3                  0.000000    1.0     0.000000     0.000000   \n",
       "EDUCATION_4                  0.000000    0.0     0.000000     0.000000   \n",
       "EDUCATION_5                  0.000000    0.0     0.000000     0.000000   \n",
       "MARRIAGE_1                   0.000000    0.0     0.000000     1.000000   \n",
       "MARRIAGE_2                   1.000000    1.0     1.000000     0.000000   \n",
       "MARRIAGE_3                   0.000000    0.0     0.000000     0.000000   \n",
       "DEFAULT                      0.000000    1.0     0.000000     0.000000   \n",
       "\n",
       "ID                              24536  \n",
       "AGE                         39.000000  \n",
       "PAY_1                        0.000000  \n",
       "PAY_2                        0.000000  \n",
       "PAY_3                        0.000000  \n",
       "PAY_4                        0.000000  \n",
       "PAY_5                        0.000000  \n",
       "PAY_6                        2.000000  \n",
       "PAY_OVERDUE_COUNT            1.000000  \n",
       "WEIGHTED_PAYMENT_HISTORY     0.333333  \n",
       "AVG_PAY_AMT               2045.833333  \n",
       "SEX_2                        0.000000  \n",
       "EDUCATION_1                  0.000000  \n",
       "EDUCATION_2                  1.000000  \n",
       "EDUCATION_3                  0.000000  \n",
       "EDUCATION_4                  0.000000  \n",
       "EDUCATION_5                  0.000000  \n",
       "MARRIAGE_1                   0.000000  \n",
       "MARRIAGE_2                   1.000000  \n",
       "MARRIAGE_3                   0.000000  \n",
       "DEFAULT                      0.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_cards_df = pd.read_parquet(\"../data/credit-cards-reduced.parquet\")\n",
    "credit_cards_df.sample(n=5).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Celowo nie ładujemy pełnego zbioru, żeby być w stanie porównać ze sobą wszystkie stworzone dotychczas rozwiązania. Regresja logistyczna działała najlepiej właśnie na tym podzbiorze i niekoniecznie oznacza to, że inne metody nie będą również w stanie wyciągnąć żadnych wniosków z pozostałych atrybutów. Wybór najlepszego zestawu cech jest dość specyficzny dla każdego modelu z osobna - to że w naszym przypadku regresja logistyczna nie dała rady z pewnych informacji skorzystać, nie może być podstawą do stwierdzenia, że nie mają one wartości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(credit_cards_df,\n",
    "                                   test_size=0.2, \n",
    "                                   random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nie popełnijmy znowu tego samego błędu jak przy KNN i zeskalujmy wszystkie zmienne, żeby uniknąć problemów z obniżoną skutecznością. Co do zasady, modele liniowe raczej wymagają skalowania zmiennych i warto jest zawsze uwzględnić to w procesie modelowania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"classifier\", LinearSVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukaw\\anaconda3\\envs\\intro-to-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('classifier',\n",
       "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train.drop(columns=\"DEFAULT\"), \n",
    "             X_train[\"DEFAULT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.416796267496112"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(X_test[\"DEFAULT\"],\n",
    "         pipeline.predict(X_test.drop(columns=\"DEFAULT\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('classifier',\n",
       "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=10000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"classifier\", LinearSVC(max_iter=10000))\n",
    "])\n",
    "pipeline.fit(X_train.drop(columns=\"DEFAULT\"), \n",
    "             X_train[\"DEFAULT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41597510373443985"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(X_test[\"DEFAULT\"],\n",
    "         pipeline.predict(X_test.drop(columns=\"DEFAULT\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nieliniowe rozszerzenia SVM\n",
    "\n",
    "Sprawdźmy może, jak dla naszego problemu zadziałają nieliniowe wersje SVM. Dogłębna analiza tych metod to temat bardzo szeroki, a sam SVM jest w stanie rozwiązać naprawdę szeroką gamę problemów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3833865814696486"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"classifier\", SVC(kernel=\"poly\"))\n",
    "])\n",
    "pipeline.fit(X_train.drop(columns=\"DEFAULT\"), \n",
    "             X_train[\"DEFAULT\"])\n",
    "f1_score(X_test[\"DEFAULT\"],\n",
    "         pipeline.predict(X_test.drop(columns=\"DEFAULT\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3625541125541126"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"classifier\", SVC(kernel=\"poly\", degree=7))\n",
    "])\n",
    "pipeline.fit(X_train.drop(columns=\"DEFAULT\"), \n",
    "             X_train[\"DEFAULT\"])\n",
    "f1_score(X_test[\"DEFAULT\"],\n",
    "         pipeline.predict(X_test.drop(columns=\"DEFAULT\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4747919725893294"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"classifier\", SVC(kernel=\"rbf\"))\n",
    "])\n",
    "pipeline.fit(X_train.drop(columns=\"DEFAULT\"), \n",
    "             X_train[\"DEFAULT\"])\n",
    "f1_score(X_test[\"DEFAULT\"],\n",
    "         pipeline.predict(X_test.drop(columns=\"DEFAULT\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
